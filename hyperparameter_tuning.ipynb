{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import regex as re\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "import math\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: random_forest_grid\n",
    "\n",
    "Purpose: Performing hyperparameter search for random forest classifier using 5X nested 5-fold Cross Validation.\n",
    "\n",
    "Input: X and y (Features and Outcome)\n",
    "\n",
    "Output: Results of the hyperparameter GridSearchCV\n",
    "'''\n",
    "\n",
    "def random_forest_grid(X, y):\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=2022)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "    [\n",
    "     ('model', RandomForestClassifier(random_state=2022))\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    search = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__min_samples_leaf':np.arange(1, 11, 1),\n",
    "      'model__criterion':[\"gini\",\"entropy\"],\n",
    "      'model__n_estimators':np.arange(11, 752, 10),\n",
    "      'model__bootstrap':[True, False]        \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search.fit(X,y)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: logistic_regression_grid\n",
    "\n",
    "Purpose: Performing hyperparameter search for logistic regression classifier using 5X nested 5-fold Cross Validation.\n",
    "\n",
    "Input: X and y (Features and Outcome)\n",
    "\n",
    "Output: Results of the hyperparameter GridSearchCV\n",
    "'''\n",
    "\n",
    "def logistic_regression_grid(X, y):\n",
    "    \n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=2022)\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "    [\n",
    "     ('model', LogisticRegression(random_state=2022, max_iter=10000))\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    search_1 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__penalty':[\"l2\"],\n",
    "      'model__C':np.arange(0.01, 1.01, 0.01),\n",
    "      'model__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "      'model__fit_intercept':[True, False]        \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search_2 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__penalty':[\"l1\"],\n",
    "      'model__C':np.arange(0.01, 1.01, 0.01),\n",
    "      'model__solver':['liblinear', 'saga'],\n",
    "      'model__fit_intercept':[True, False]        \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search_3 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__penalty':[\"elasticnet\"],\n",
    "      'model__C':np.arange(0.01, 1.01, 0.01),\n",
    "      'model__l1_ratio': np.arange(0.1, 1, 0.1),\n",
    "      'model__solver':['saga'],\n",
    "      'model__fit_intercept':[True, False]        \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search_4 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__penalty':[\"none\"],\n",
    "      'model__solver':['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "      'model__fit_intercept':[True, False]        \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search_1.fit(X,y)\n",
    "    search_2.fit(X,y)\n",
    "    search_3.fit(X,y)\n",
    "    search_4.fit(X,y)\n",
    "    \n",
    "    \n",
    "    if (((search_1.best_score_ > search_2.best_score_) & (search_1.best_score_ > search_3.best_score_)) & (search_1.best_score_ > search_4.best_score_)):\n",
    "        return search_1\n",
    "    \n",
    "    elif ((search_2.best_score_ > search_3.best_score_) & (search_2.best_score_ > search_4.best_score_)):\n",
    "        return search_2\n",
    "    \n",
    "    elif (search_3.best_score_ > search_4.best_score_):\n",
    "        return search_3\n",
    "    \n",
    "    else:\n",
    "        return search_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: support_vector_machine_grid\n",
    "\n",
    "Purpose: Performing hyperparameter search for support vector machine classifier using 5X nested 5-fold Cross Validation.\n",
    "\n",
    "Input: X and y (Features and Outcome)\n",
    "\n",
    "Output: Results of the hyperparameter GridSearchCV\n",
    "'''\n",
    "\n",
    "def support_vector_machine_grid(X, y):\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=2022)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "    [\n",
    "     ('model', SVC(random_state=2022))\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    search_1 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__gamma': ['scale', 'auto'],\n",
    "      'model__coef0': [0, 1, 2],\n",
    "      'model__C': np.arange(0.01, 1.001, 0.01),\n",
    "      'model__kernel': ['poly'],\n",
    "      'model__degree': [2, 3],\n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "        \n",
    "    search_2 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__gamma': ['scale', 'auto'],\n",
    "      'model__coef0': [0, 0.5, 1, 1.5, 2],\n",
    "      'model__C': np.arange(0.01, 1.001, 0.01),\n",
    "      'model__kernel': ['sigmoid'],\n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "        \n",
    "    search_3 = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__gamma': ['scale', 'auto'],\n",
    "      'model__C': np.arange(0.005, 1.001, 0.005),\n",
    "      'model__kernel': ['linear', 'rbf'],\n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search_1.fit(X,y)\n",
    "    search_2.fit(X,y)\n",
    "    search_3.fit(X,y)\n",
    "        \n",
    "    if ((search_1.best_score_ > search_2.best_score_) & (search_1.best_score_ > search_3.best_score_)):\n",
    "        return search_1\n",
    "        \n",
    "    elif (search_2.best_score_ > search_3.best_score_):\n",
    "        return search_2\n",
    "        \n",
    "    else:\n",
    "        return search_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: KNN_grid\n",
    "\n",
    "Purpose: Performing hyperparameter search for K-Nearest Neighbors classifier using 5X nested 5-fold Cross Validation.\n",
    "\n",
    "Input: X and y (Features and Outcome)\n",
    "\n",
    "Output: Results of the hyperparameter GridSearchCV\n",
    "'''\n",
    "\n",
    "def KNN_grid(X, y):\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=2022)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "    [\n",
    "     ('model', KNeighborsClassifier())\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    search = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__n_neighbors':np.arange(1, 128, 2),\n",
    "      'model__weights':[\"uniform\",\"distance\"],\n",
    "      'model__leaf_size':np.arange(1, 33, 3),\n",
    "      'model__p':[1, 2]        \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search.fit(X,y)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: naive_bayes_grid\n",
    "\n",
    "Purpose: Performing hyperparameter search for Naive Bayes classifier using 5X nested 5-fold Cross Validation.\n",
    "\n",
    "Input: X and y (Features and Outcome)\n",
    "\n",
    "Output: Results of the hyperparameter GridSearchCV\n",
    "'''\n",
    "\n",
    "def naive_bayes_grid(X, y):\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=2022)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "    [\n",
    "     ('model', GaussianNB())\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    search = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__var_smoothing': np.logspace(0,-11, num=3000)    \n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search.fit(X,y)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: light_gbm_grid\n",
    "\n",
    "Purpose: Performing hyperparameter search for Light Gradient Boosting classifier using 5X nested 5-fold Cross Validation.\n",
    "\n",
    "Input: X and y (Features and Outcome)\n",
    "\n",
    "Output: Results of the hyperparameter GridSearchCV\n",
    "'''\n",
    "\n",
    "def light_gbm_grid(X, y):\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=2022)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "    [\n",
    "     ('model', LGBMClassifier(random_state=2022))\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    search = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = {\n",
    "      'model__n_estimators': [20, 100, 400],\n",
    "      'model__learning_rate': [0.005, 0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "      'model__num_leaves': [5, 10, 20, 35, 50, 75],\n",
    "      'model__min_child_samples':[5, 10, 20, 30, 50, 75],\n",
    "      'model__max_bin': [20, 50, 100, 255, 400]\n",
    "     },\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=rkf,\n",
    "    verbose=3\n",
    "    )\n",
    "    \n",
    "    search.fit(X,y)\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dataframe for 70_30 feature selected data.\n",
    "\n",
    "name = \"../data/feature_selected_train_dataset_70_30.csv\"\n",
    "df = pd.read_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate into features and outcomes\n",
    "\n",
    "X_train = df.drop(['outcome'], axis=1, inplace=False)\n",
    "y_train = df[\"outcome\"]\n",
    "\n",
    "## Scale X with standard scaler for models that require it.\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 3000 candidates, totalling 75000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c2268a00bf25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Perform hyperparameter search for random forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msearch_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_forest_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## Display best ROC-AUC score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ROC-AUC of the best random forest model was:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-85ba34611dd6>\u001b[0m in \u001b[0;36mrandom_forest_grid\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Perform hyperparameter search for random forest\n",
    "search_rf = random_forest_grid(X_train, y_train)\n",
    "\n",
    "## Display best ROC-AUC score\n",
    "print(\"ROC-AUC of the best random forest model was:\", search_rf.best_score_)\n",
    "\n",
    "## Display parameters for best model\n",
    "print(\"Hyperparameters of best random forest model were: \\n\\n\", search_rf.best_params_)\n",
    "\n",
    "## Save best random forest classifier model for future usage\n",
    "joblib.dump(search_rf.best_estimator_, '../top_models/best_random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 1000 candidates, totalling 25000 fits\n",
      "Fitting 25 folds for each of 400 candidates, totalling 10000 fits\n",
      "Fitting 25 folds for each of 1800 candidates, totalling 45000 fits\n",
      "Fitting 25 folds for each of 8 candidates, totalling 200 fits\n",
      "ROC-AUC of the best logistic regression model was: 0.8413888474495735\n",
      "Hyperparameters of best logistic regression model were: \n",
      "\n",
      " {'model__C': 0.01, 'model__fit_intercept': True, 'model__penalty': 'l2', 'model__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "## Perform hyperparameter search for logistic regression\n",
    "search_logreg = logistic_regression_grid(X_train_scaled, y_train)\n",
    "\n",
    "## Display best accuracy score\n",
    "print(\"Accuracy of the best logistic regression model was:\", search_logreg.best_score_)\n",
    "\n",
    "## Display parameters for best model\n",
    "print(\"Hyperparameters of best logistic regression model were: \\n\\n\", search_logreg.best_params_)\n",
    "\n",
    "## Save best Logistic Regression classifier model for future usage\n",
    "joblib.dump(search_logreg.best_estimator_, '../top_models/best_logistic_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 1200 candidates, totalling 30000 fits\n",
      "Fitting 25 folds for each of 1000 candidates, totalling 25000 fits\n",
      "Fitting 25 folds for each of 800 candidates, totalling 20000 fits\n",
      "Accuracy of the best support vector machine model was: 0.7780026990553306\n",
      "Hyperparameters of best support vector machine model were: \n",
      "\n",
      " {'model__C': 0.29000000000000004, 'model__coef0': 0.5, 'model__gamma': 'auto', 'model__kernel': 'sigmoid'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../top_models/best_support_vector_machine.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Perform hyperparameter search for logistic regression\n",
    "search_svc = support_vector_machine_grid(X_train_scaled, y_train)\n",
    "\n",
    "## Display best accuracy score\n",
    "print(\"Accuracy of the best support vector machine model was:\", search_svc.best_score_)\n",
    "\n",
    "## Display parameters for best model\n",
    "print(\"Hyperparameters of best support vector machine model were: \\n\\n\", search_svc.best_params_)\n",
    "\n",
    "## Save best Support Vector Machine classifier model for future usage\n",
    "joblib.dump(search_svc.best_estimator_, '../top_models/best_support_vector_machine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 2816 candidates, totalling 70400 fits\n",
      "ROC-AUC of the best K-Nearest Neighbor model was: 0.840535026642277\n",
      "Hyperparameters of best K-Nearest Neighbor model were: \n",
      "\n",
      " {'model__leaf_size': 1, 'model__n_neighbors': 111, 'model__p': 2, 'model__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "## Perform hyperparameter search for logistic regression\n",
    "search_knn = KNN_grid(X_train_scaled, y_train)\n",
    "\n",
    "## Display best accuracy score\n",
    "print(\"Accuracy of the best K-Nearest Neighbor model was:\", search_knn.best_score_)\n",
    "\n",
    "## Display parameters for best model\n",
    "print(\"Hyperparameters of best K-Nearest Neighbor model were: \\n\\n\", search_knn.best_params_)\n",
    "\n",
    "## Save best KNN classifier model for future usage\n",
    "joblib.dump(search_knn.best_estimator_, '../top_models/best_KNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 3000 candidates, totalling 75000 fits\n",
      "Accuracy of the best Naive Bayes model was: 0.7406207827260458\n",
      "Hyperparameters of best Naive Bayes model were: \n",
      "\n",
      " {'model__var_smoothing': 4.126088252678016e-06}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../top_models/best_naive_bayes.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Perform hyperparameter search for logistic regression\n",
    "search_naive_bayes = naive_bayes_grid(X_train, y_train)\n",
    "\n",
    "## Display best accuracy score\n",
    "print(\"Accuracy of the best Naive Bayes model was:\", search_naive_bayes.best_score_)\n",
    "\n",
    "## Display parameters for best model\n",
    "print(\"Hyperparameters of best Naive Bayes model were: \\n\\n\", search_naive_bayes.best_params_)\n",
    "\n",
    "## Save best Naive Bayes classifier model for future usage\n",
    "joblib.dump(search_naive_bayes.best_estimator_, '../top_models/best_naive_bayes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 3240 candidates, totalling 81000 fits\n",
      "Accuracy of the best Light GBM model was: 0.7406477732793522\n",
      "Hyperparameters of best Light GBM model were: \n",
      "\n",
      " {'model__learning_rate': 0.005, 'model__max_bin': 20, 'model__min_child_samples': 20, 'model__n_estimators': 400, 'model__num_leaves': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../top_models/best_light_gbm.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Perform hyperparameter search for logistic regression\n",
    "search_light_gbm = light_gbm_grid(X_train, y_train)\n",
    "\n",
    "## Display best accuracy score\n",
    "print(\"Accuracy of the best Light GBM model was:\", search_light_gbm.best_score_)\n",
    "\n",
    "## Display parameters for best model\n",
    "print(\"Hyperparameters of best Light GBM model were: \\n\\n\", search_light_gbm.best_params_)\n",
    "\n",
    "## Save best Light GBM classifier model for future usage\n",
    "joblib.dump(search_light_gbm.best_estimator_, '../top_models/best_light_gbm.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
